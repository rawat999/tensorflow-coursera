{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "coursera_1204.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOnhJl08s5XOn3cSOaAKaLg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rawatpremsingh999/tensorflow-coursera/blob/master/coursera_1204.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDBP5rAAmjmW"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doxiRgO1Rsm9"
      },
      "source": [
        "**Load Fashion MNIST dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mp6agLMm5FS"
      },
      "source": [
        "# load fashion MNIST dataset\r\n",
        "\r\n",
        "f_MNIST = keras.datasets.fashion_mnist\r\n",
        "(train_images, train_labels),(test_images, test_labels) = f_MNIST.load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJhDizZRR9km"
      },
      "source": [
        "**See what is in the train_image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wndHSuNnehP",
        "outputId": "a1b7085a-6b66-44f5-bb07-4152c81d8253"
      },
      "source": [
        "train_images[0]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
              "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
              "          1,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
              "          0,   3],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
              "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
              "         10,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
              "         72,  15],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
              "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
              "        172,  66],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
              "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
              "        229,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
              "        173,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
              "        202,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
              "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
              "        209,  52],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
              "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
              "        167,  56],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
              "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
              "         92,   0],\n",
              "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
              "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
              "         77,   0],\n",
              "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
              "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
              "        159,   0],\n",
              "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
              "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
              "        215,   0],\n",
              "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
              "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
              "        246,   0],\n",
              "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
              "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
              "        225,   0],\n",
              "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
              "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
              "        229,  29],\n",
              "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
              "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
              "        230,  67],\n",
              "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
              "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
              "        206, 115],\n",
              "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
              "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
              "        210,  92],\n",
              "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
              "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
              "        170,   0],\n",
              "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
              "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA6JZp0pninG",
        "outputId": "8762d4f2-b3fd-43a6-8fca-c37df16aff3c"
      },
      "source": [
        "train_labels[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s_H6fWBR0bK"
      },
      "source": [
        "**Visualise a particular image in training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "fhZ0S-rFnrTS",
        "outputId": "4d58c92d-81b6-4040-f781-c33860ec66c7"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.imshow(train_images[1300])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe43f84d5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIc-MZCyqdAi",
        "outputId": "971fca54-6ea5-4db8-9f38-918f2409f3bd"
      },
      "source": [
        "train_labels[1300]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "KYO10BGSqhJm",
        "outputId": "b1a3e43d-e2fa-40a2-b576-539d3d4997e6"
      },
      "source": [
        "np.set_printoptions(linewidth=200)\r\n",
        "plt.imshow(train_images[4300])\r\n",
        "print(train_labels[4300])\r\n",
        "print(train_images[4300])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "[[  0   0   0   0   0   0   0   0   0   0 108 181 166 202 175 163 204 209 180 175   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 132 178 193 184 199 207 209 185 194 214  47   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 154 186 196 202 202 191 196 201 189 217  90   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 195 187 184 180 185 190 180 190 181 217 106   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  76 198 178 185 181 201 194 181 225 188 192 105   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 172 196 175 171 171 209 180 197 230 170 181 100   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 208 189 198 192 191 220 220 220 216 169 210  82   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  34 226 191 186 163 192 120 150 249 209 203 231  50   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  72 222 189 180 177 238   0  59 255 214 209 230   9   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  95 220 185 183 211 200   0  24 255 220 216 221   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 108 223 178 176 230  95   0   0 248 218 218 195   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 120 220 178 177 220   0   0   0 238 215 216 163   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 106 217 174 186 138   0   0   0 190 212 215 126   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 124 210 169 190 117   0   0   0 212 208 197 111   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 135 208 170 192  86   0   0   0 185 217 205 115   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  96 228 176 195  26   0   3   0 126 220 215 126   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  50 237 176 195  49   0   5   0  89 218 212 155   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 229 179 195  89   0   3   0  89 211 205 163   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 207 192 189 152   0   1   0 107 213 200 155   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 171 199 186 193   0   0   0 100 207 196 157   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 101 202 186 169   0   0   0  60 202 203 147   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  36 195 180 168   0   0   0  87 205 210 108   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   6 189 176 173   0   0   0 105 205 211  93   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 140 179 177   1   0   0 102 203 193  38   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 160 183 171  29   0   0  97 206 203  72   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   5   0 117 168 172  41   0   0  70 200 192 111   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   4   0  24 187 206  94   0   0  79 216 212  62   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   2   0   0 100 133  38   0   0   1 143 135  22   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqx7CmeJrVzK"
      },
      "source": [
        "**Normalizing Images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quRnByRIqqZg"
      },
      "source": [
        "train_images = train_images / 255.0\r\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O32m4xXvrt8V"
      },
      "source": [
        "**Design the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAAvDnmVrkZU"
      },
      "source": [
        "model = tf.keras.Sequential()\r\n",
        "model.add(keras.layers.Flatten())\r\n",
        "model.add(keras.layers.Dense(128,activation=tf.nn.relu))\r\n",
        "model.add(keras.layers.Dense(10,activation=tf.nn.softmax))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-aVKU68Ug5g"
      },
      "source": [
        "**Sequential**: That defines a SEQUENCE of layers in the neural network\r\n",
        "\r\n",
        "**Flatten**: Remember earlier where our images were a square, when you printed them out? Flatten just takes that square and turns it into a 1 dimensional set.\r\n",
        "\r\n",
        "**Dense**: Adds a layer of neurons\r\n",
        "\r\n",
        "Each layer of neurons need an **activation function** to tell them what to do. There's lots of options, but just use these for now. \r\n",
        "\r\n",
        "**Relu** effectively means \"If X>0 return X, else return 0\" -- so what it does it it only passes values 0 or greater to the next layer in the network.\r\n",
        "\r\n",
        "**Softmax** takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u71gsJJXs4lz"
      },
      "source": [
        "**Define Model Compilation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AlEYENps3iO"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UphWc5LUtlMQ"
      },
      "source": [
        "**Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtHYeGI7sx4d",
        "outputId": "e80e9cd8-d150-4a91-896c-7b6b3ec3fb72"
      },
      "source": [
        "model.fit(x = train_images, y = train_labels, epochs= 10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6252 - accuracy: 0.7830\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3855 - accuracy: 0.8600\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3348 - accuracy: 0.8782\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3097 - accuracy: 0.8858\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2927 - accuracy: 0.8912\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2737 - accuracy: 0.8982\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2645 - accuracy: 0.9011\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2521 - accuracy: 0.9062\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2454 - accuracy: 0.9086\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2327 - accuracy: 0.9135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe43b360358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Mab0vLuWh9"
      },
      "source": [
        "**Evaluate the Model on Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R_xWGg0t606",
        "outputId": "2cb54cf3-a07b-4963-d943-1b71ecff99d5"
      },
      "source": [
        "model.evaluate(x = test_images, y = test_labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33845916390419006, 0.8781999945640564]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwE-dISkXL4j"
      },
      "source": [
        "**Predict the Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ID7-55vhXTU_",
        "outputId": "fdfe12c4-c10e-454f-aea3-5dfabc4d1ddc"
      },
      "source": [
        "classifications = model.predict(test_images)\r\n",
        "\r\n",
        "print(classifications[0]) # probabilities of output belongs to that class"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.0786256e-09 4.7239322e-08 1.4278494e-08 3.5094219e-09 2.4493511e-08 1.7620856e-03 2.1063371e-07 7.1988655e-03 2.5023252e-07 9.9103856e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf9bSiahXXRt",
        "outputId": "896c5bbb-9142-430b-e5b6-57b4704fb515"
      },
      "source": [
        "print(test_labels[0]) # actual output"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQKdD-O6Xh8w",
        "outputId": "abdc8e0f-66ff-49ef-e717-16bc0cee2451"
      },
      "source": [
        "# round to 4 decimal values\r\n",
        "for i in classifications[0]:\r\n",
        "  print(round(i,4),end='   ') "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0   0.0   0.0   0.0   0.0   0.0018   0.0   0.0072   0.0   0.991   "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-20ePzKZOLD"
      },
      "source": [
        "**Labels**\r\n",
        "\r\n",
        "Each training and test example is assigned to one of the following labels:\r\n",
        "\r\n",
        "Label \\: Description\r\n",
        "\r\n",
        "0.   T-shirt/top\r\n",
        "1.   Trouser\r\n",
        "2.   Pullover\r\n",
        "3.   Dress\r\n",
        "4.   Coat\r\n",
        "5.   Sandal\r\n",
        "6.   Shirt\r\n",
        "7.   Sneaker\r\n",
        "8.   Bag\r\n",
        "9.   Ankel Boot\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nspYTrPMa7A9"
      },
      "source": [
        "### Now experiment with different neurons in the dense layer (e.g. 512 or 1024)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6yW5dFFX_ss",
        "outputId": "230aadf3-db9a-49c7-d8e1-03ab29c2c06e"
      },
      "source": [
        "# 512 neurons in dense layer\r\n",
        "model1 = tf.keras.Sequential([keras.layers.Flatten(),\r\n",
        "                              keras.layers.Dense(512,activation='relu'),\r\n",
        "                              keras.layers.Dense(10,activation='softmax')])\r\n",
        "\r\n",
        "model1.compile(optimizer = 'adam',loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])\r\n",
        "\r\n",
        "model1.fit(train_images,train_labels,epochs=10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5890 - accuracy: 0.7917\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3679 - accuracy: 0.8641\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3246 - accuracy: 0.8794\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3008 - accuracy: 0.8868\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2779 - accuracy: 0.8967\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2679 - accuracy: 0.8993\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2520 - accuracy: 0.9056\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2396 - accuracy: 0.9093\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2301 - accuracy: 0.9137\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2201 - accuracy: 0.9160\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe438c694a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs6fv6p4cNlK",
        "outputId": "65fce45b-e11d-4201-ea4e-afc14ebd0bda"
      },
      "source": [
        "model1.evaluate(test_images,test_labels)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3420 - accuracy: 0.8835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3420184552669525, 0.8834999799728394]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzx4kX21eAT9"
      },
      "source": [
        "**Note:**\r\n",
        "Increase to 512 neurons in dense layer, Training takes longer but it is more accurate than previous neural network model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmyvHpVBcpFM",
        "outputId": "4ec0d9fc-8781-478d-fa36-6f5bc2b9b828"
      },
      "source": [
        "# 1024 neurons in dense layers\r\n",
        "model2 = tf.keras.Sequential([keras.layers.Flatten(),\r\n",
        "                              keras.layers.Dense(1024,activation='sigmoid'),\r\n",
        "                              keras.layers.Dense(10,activation='softmax')])\r\n",
        "\r\n",
        "model2.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics= ['accuracy'])\r\n",
        "\r\n",
        "model2.fit(train_images,train_labels,epochs=10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.6257 - accuracy: 0.7789\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.3943 - accuracy: 0.8554\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.3459 - accuracy: 0.8733\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.3155 - accuracy: 0.8836\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2874 - accuracy: 0.8925\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2653 - accuracy: 0.9010\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2496 - accuracy: 0.9053\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2417 - accuracy: 0.9079\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2196 - accuracy: 0.9163\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2083 - accuracy: 0.9208\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe436b17278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBa2mA4Jdt3_",
        "outputId": "c9207c8c-54ea-471a-d612-1a30ed18f155"
      },
      "source": [
        "model2.evaluate(test_images,test_labels)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3204 - accuracy: 0.8900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3203895390033722, 0.8899999856948853]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQW7F8FqeaIr"
      },
      "source": [
        "**Note:** Again it takes more time to train but it is more accurate than previous networks!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es6fB-l7gg-o"
      },
      "source": [
        "### Now experiment with additional number of layers in the network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srD4HVQBeYjV",
        "outputId": "49db91dc-a013-473d-e5aa-aab4fbc00f87"
      },
      "source": [
        "# Design Network\r\n",
        "model3 = tf.keras.Sequential()\r\n",
        "model3.add(keras.layers.Flatten())\r\n",
        "model3.add(keras.layers.Dense(512,activation='relu'))\r\n",
        "model3.add(keras.layers.Dense(64,activation='relu'))\r\n",
        "model3.add(keras.layers.Dense(10,activation='softmax'))\r\n",
        "\r\n",
        "# Define Compilation of Network\r\n",
        "model3.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\r\n",
        "\r\n",
        "# Train the Network\r\n",
        "model3.fit(train_images,train_labels,epochs=10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5996 - accuracy: 0.7884\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3668 - accuracy: 0.8642\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3201 - accuracy: 0.8813\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3003 - accuracy: 0.8879\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2813 - accuracy: 0.8948\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2655 - accuracy: 0.9011\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2565 - accuracy: 0.9031\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2471 - accuracy: 0.9060\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2273 - accuracy: 0.9143\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2203 - accuracy: 0.9160\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe4359ce518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRnXYaPJh_sv",
        "outputId": "b3e33225-1033-4c83-c02f-b7aa493e16d4"
      },
      "source": [
        "model3.evaluate(test_images,test_labels)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3474 - accuracy: 0.8803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3473920226097107, 0.880299985408783]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmmfJKRXiVpE"
      },
      "source": [
        "There isn't a significant impact -- because this is relatively simple data. For far more complex data (including color images to be classified as flowers that you'll see in the next lesson), extra layers are often necessary. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PENxgzZ_lOkR"
      },
      "source": [
        "### **Stop Training** when we get desired result:\r\n",
        "stop the training when I reach a desired value using callback function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaUBz2vciUOK",
        "outputId": "956ef31b-3e30-4699-cf05-aa2e90cfc874"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\r\n",
        "  def on_epoch_end(self,epoch,logs={}):\r\n",
        "    if(logs.get('loss')<0.25):\r\n",
        "      print(\"\\nReached at less than 0.25 loss so cancelling training!!! \")\r\n",
        "      self.model.stop_training = True\r\n",
        "\r\n",
        "callbacks = myCallback()\r\n",
        "\r\n",
        "model4 = tf.keras.Sequential([keras.layers.Flatten(),\r\n",
        "                              keras.layers.Dense(128,activation='relu'),\r\n",
        "                              keras.layers.Dense(10,activation='softmax')])\r\n",
        "\r\n",
        "model4.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\r\n",
        "\r\n",
        "model4.fit(train_images,train_labels,epochs=20,callbacks=[callbacks])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6313 - accuracy: 0.7787\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3829 - accuracy: 0.8591\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3356 - accuracy: 0.8791\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3134 - accuracy: 0.8844\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2926 - accuracy: 0.8931\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2717 - accuracy: 0.8995\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2663 - accuracy: 0.8997\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2573 - accuracy: 0.9049\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2417 - accuracy: 0.9100\n",
            "\n",
            "Reached at less than 0.25 loss so cancelling training!!! \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe432b75208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riMH8JZoqjUd"
      },
      "source": [
        "#### Stop when we reached certain level of **accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkDtnpD7qiWC",
        "outputId": "1ee8e6c9-a5f3-4aab-b299-5d59534009e0"
      },
      "source": [
        "class meracallback(tf.keras.callbacks.Callback):  # call name can be anything as we want\r\n",
        "  def on_epoch_end(self,epoch,logs={}): # function name must be same 'on_epoch_end'\r\n",
        "    if(logs.get('accuracy')>0.9):\r\n",
        "      print(\"\\nReached at 90% accuracy so cancelling training!\")\r\n",
        "      self.model.stop_training = True\r\n",
        "\r\n",
        "callbacks = meracallback()\r\n",
        "\r\n",
        "model5 = tf.keras.Sequential([keras.layers.Flatten(),\r\n",
        "                              keras.layers.Dense(128,activation='relu'),\r\n",
        "                              keras.layers.Dense(10,activation='softmax')])\r\n",
        "\r\n",
        "model5.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\r\n",
        "\r\n",
        "model5.fit(train_images,train_labels,epochs=20,callbacks=[callbacks])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6300 - accuracy: 0.7827\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3765 - accuracy: 0.8658\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3364 - accuracy: 0.8758\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3140 - accuracy: 0.8828\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2993 - accuracy: 0.8893\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2854 - accuracy: 0.8940\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2646 - accuracy: 0.9019\n",
            "\n",
            "Reached at 90% accuracy so cancelling training!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe432c140b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grR25CjWsALe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}