{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "coursera_1304.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPEyZnX4on6NDaOvxyDXh2V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rawatpremsingh999/tensorflow-coursera/blob/master/coursera_1304.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjVRnKcQmnBI"
      },
      "source": [
        "## Improving Computer Vision Accuracy using Convolutions Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLoom0VAnTn1"
      },
      "source": [
        "# import necessary libraries\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cncnGiB0nHBk"
      },
      "source": [
        "### Using DNN (Deep Neural Network)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciulPGWMm4kn",
        "outputId": "795fb489-3f4f-4911-9c44-9bd03e5a6205"
      },
      "source": [
        "# load data\r\n",
        "mnist = tf.keras.datasets.fashion_mnist\r\n",
        "(training_images,training_labels),(test_images,test_labels) = mnist.load_data()\r\n",
        "\r\n",
        "# normalising data\r\n",
        "training_images = training_images/255.0\r\n",
        "test_images = test_images/255.0\r\n",
        "\r\n",
        "# Design the model\r\n",
        "dnn_model = tf.keras.Sequential()\r\n",
        "dnn_model.add(keras.layers.Flatten())\r\n",
        "dnn_model.add(keras.layers.Dense(128,activation='relu'))\r\n",
        "dnn_model.add(keras.layers.Dense(10,activation='softmax'))\r\n",
        "\r\n",
        "# model compilation\r\n",
        "dnn_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\r\n",
        "\r\n",
        "# model training\r\n",
        "dnn_model.fit(training_images,training_labels,epochs=10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6281 - accuracy: 0.7807\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3884 - accuracy: 0.8618\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3475 - accuracy: 0.8729\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3098 - accuracy: 0.8849\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2919 - accuracy: 0.8920\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2790 - accuracy: 0.8966\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2644 - accuracy: 0.9013\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2551 - accuracy: 0.9049\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2421 - accuracy: 0.9083\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2371 - accuracy: 0.9107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f16300ac780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhoQRLdPqZZg",
        "outputId": "4249b5d5-d6db-40b4-ee10-20ba3561e484"
      },
      "source": [
        "dnn_model.evaluate(test_images,test_labels)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3269 - accuracy: 0.8859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3268657326698303, 0.8859000205993652]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U2K8JX_qvKl",
        "outputId": "79820299-ef0e-4abc-ccdc-9125ff780159"
      },
      "source": [
        "dnn_model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muC7ZZwBrPh0"
      },
      "source": [
        "## CNN (Convolution Neural Network)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3uIKTY2rvLL"
      },
      "source": [
        "**NOTE:**\r\n",
        "\r\n",
        "*   Convolutions narrow down the content of the image to focus on specific, distinct, details.\r\n",
        "*   we take an array (usually 3x3 or 5x5) and pass it over the image. By changing the underlying pixels based on the formula within that matrix, we can do things like edge detection\r\n",
        "*   we will just train on the highlighted features.\r\n",
        "*   **Convolutional Neural Networks:** Add some layers to do convolution before we have the dense layers, and then the information going to the dense layers is more focussed, and possibly more accurate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb_vanaprOMR",
        "outputId": "0d82f1f6-b5cc-4b06-9601-4dbb9f30d5a1"
      },
      "source": [
        "# load data\r\n",
        "mnist = tf.keras.datasets.fashion_mnist\r\n",
        "(training_images,training_labels),(test_images,test_labels) = mnist.load_data()\r\n",
        "\r\n",
        "# Reshape 2-D image in 4-D tensor\r\n",
        "training_images = training_images.reshape(60000,28,28,1)\r\n",
        "test_images     = test_images.reshape(10000,28,28,1)\r\n",
        "\r\n",
        "# normalising data\r\n",
        "training_images = training_images/255.0\r\n",
        "test_images = test_images/255.0\r\n",
        "\r\n",
        "# Design Network\r\n",
        "model = keras.Sequential()\r\n",
        "model.add(keras.layers.Conv2D(64,3,activation='relu',input_shape=(28,28,1)))\r\n",
        "model.add(keras.layers.MaxPooling2D(2,2))\r\n",
        "model.add(keras.layers.Conv2D(64,3,activation='relu'))\r\n",
        "model.add(keras.layers.MaxPooling2D(2,2))\r\n",
        "\r\n",
        "model.add(keras.layers.Flatten())\r\n",
        "model.add(keras.layers.Dense(128,activation='relu'))\r\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))\r\n",
        "\r\n",
        "\r\n",
        "# Define model compilation\r\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\r\n",
        "\r\n",
        "# Train model\r\n",
        "model.fit(training_images,training_labels,epochs=10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 6s 2ms/step - loss: 0.5921 - accuracy: 0.7854\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2995 - accuracy: 0.8889\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2542 - accuracy: 0.9069\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2130 - accuracy: 0.9212\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1888 - accuracy: 0.9301\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1631 - accuracy: 0.9388\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1432 - accuracy: 0.9460\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1267 - accuracy: 0.9529\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1060 - accuracy: 0.9604\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0937 - accuracy: 0.9649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1620457c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zF38Xp_Nqzn4",
        "outputId": "0e9d648f-ad52-45a2-8038-8456a2fe6b4c"
      },
      "source": [
        "# Test loss and accuracy\r\n",
        "model.evaluate(test_images,test_labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3265 - accuracy: 0.9089\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.32652023434638977, 0.9089000225067139]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyj4vYJBzRKv",
        "outputId": "92aee837-345f-4dd7-f5f8-ee9f0494df9a"
      },
      "source": [
        "# model architecture\r\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5fYKFeN7P8Q"
      },
      "source": [
        "## Visualising the Convolutions and Poolings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A53XkyoI8BID"
      },
      "source": [
        "\r\n",
        "\r\n",
        "*   print(test_labels[:100]) shows us the first 100 labels in the test set\r\n",
        "*   take index 2,3,5 and 97 (all labels are 1)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfp2mjemzWbT",
        "outputId": "53394470-7562-4069-d543-4537486f78b3"
      },
      "source": [
        "print(test_labels[:100])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
            " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
            " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "937qR6U18cNG",
        "outputId": "fdf979f4-a9d1-4681-cb7d-1bbd7289c03b"
      },
      "source": [
        "f, axarr = plt.subplots(4,4)\r\n",
        "\r\n",
        "FIRST_IMAGE=2\r\n",
        "SECOND_IMAGE=3\r\n",
        "THIRD_IMAGE=5\r\n",
        "FOURTH_IMAGE=97\r\n",
        "\r\n",
        "CONVOLUTION_NUMBER = 1\r\n",
        "\r\n",
        "layer_outputs = [layer.output for layer in model.layers]\r\n",
        "activation_model = keras.models.Model(inputs = model.input, outputs = layer_outputs)\r\n",
        "\r\n",
        "for x in range(0,4):\r\n",
        "  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\r\n",
        "  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\r\n",
        "  axarr[0,x].grid(False)\r\n",
        "  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\r\n",
        "  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\r\n",
        "  axarr[1,x].grid(False)\r\n",
        "  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\r\n",
        "  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\r\n",
        "  axarr[2,x].grid(False)\r\n",
        "  f4 = activation_model.predict(test_images[FOURTH_IMAGE].reshape(1, 28, 28, 1))[x]\r\n",
        "  axarr[3,x].imshow(f4[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\r\n",
        "  axarr[3,x].grid(False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAD7CAYAAADemNc5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO29ebwkVZXg/z0Rub2l3l4btRcUBQWICKIIA6WIIoNN2yKC3Taj2Ngq89HWdkTnM8iH7l839rjxa2idUmnAUQGXxlJRG0FcELGKslhLioIqoPa93pprnPkj4r3KzMol3suMzMj37rc++am4ETcjTp58ee6NE+eeI6qKwWAwGOqL1WwBDAaDYTpijKvBYDAEgDGuBoPBEADGuBoMBkMAGONqMBgMAWCMq8FgMARATcZVRC4WkedEZIuIXF8voQwGg6HVmbJxFREbuA14G7AKuEpEVtVLMIMZvILE6NYQNJEa3ns2sEVVXwQQkbuBy4Bny70hYbVph9Xl6+Ti/a9AbyxL18md5Lbt49nDQs5Jo2RrEH38GhG6rT4sqd53xBkk6Yz56Fkf8gavi4DtwDoRWauqJfU7Kd0WfYqlp3dMbD/++NapCVyCPnuOr35h1633nppX25x55rJj9tVT35VQ1Ybpd7LUQ7fjlNJxKeqp93K6rcW4LgBeyWtvB15X3ElErgWuBWi3ZvG2riurntiSo1NqB3jL/CHe9ZWNbPqfJ3HBb7czkt5NzjlSg+gukcgAF7a/i4Rd/e/up4N313y9STKpwavD6vKlW4C4Xdhes+7sie2IdfWUhC2FX3nCrtuj2JUPV+Gxdf9wzL566rs8uQZco1Zq0+04pXRcivrpvbxuA3+gpaprVPUsVT0rIW2+3uMopBwl5Si2wObBDv7w8cXc+cxJDCY318WwtgClBq8F+R1E5FoRWS8i65M61lDhWpyqujWUppo7RUTiInKPd/wxEVnaeCnDQS3GdQewKK+90NtXN1RhKKPsS1lsOjCbAymIRgYQSdTzMi3LVAYug3/yB69myxIGfD5nuQY4pKonAF8CPtdYKcNDLW6BdcAKEVmGa1SvBN5TF6kAW4SsKnsySQ5nbQ6n2ziQzrAkfjY7Mk8xln65XpcKK4ENXk6Rh+uv+h6rx2lbCV+6VdU1wBqoj1/wUwtbXs9+3CmXATd6298DbhUR0RmYIWrKM1dVzQLXAT8HNgH3quoz9RIMwLag147hqPJEZhebrM3sc7aSyQ3V8zJhZWLwEpEY7uC1tskyTReMbqeGH3fKRB/PRhwB+otPNBPuCmqZuaKq9wP310mWY7BF6IvZDI9l+dPoT3Efb4FqKzjoa0NVsyIyPnjZwO31HrxmKka3zafedwVhpCbjGjRRCxa2O6ScGIxl0Yknc9PyuziGoAavs/uTBe0Pb/5GvS8ReoKeGExT/LhTxvtsF5EI0A0caIx44SLUy18jAv3xDD0xQVGYeBkMhibgx52yFhiPc7oceGgm+lsh5DNXBXIq5GbkV2OYbnxh5781W4SaKOdOEZGbgPWquhb4BvBNEdkCHMQ1wDOSUBtXwZ1ah3ZpicEwwyjlTlHVG/K2k8C7Gi3XOI1ZlOGPUBvXiAUDiSQ9Y9FmizKtmN8x0mwRDIZpT6h9rgJELYeIgJj5q8FgaCFCbVwVyDniBWAZDAZD6xBq45pxYHeyjcNpQaw2xJcXwyYamY1tdQcun8FgMJQj1D7X0Sw8ui/KvnSSzthxjGb2k81VDpmL2F2cFFvNftnJrpFHGiRpa/Ho3r6C9qzEiontoeTzFd/7vdOvKmhf/sR36ieYwTCNCPXM1RLoiAgJK4LigA8HQSzSzZltczjeWRm8gAaDwVCGUBtXW6A/rnRHbLJOCtXqxrU7soAL5w1xRncbJojLYDA0i1C7BVRhJCtk1KErehxHcMilq+dyjdk5fOS/nrHsKUr6f7a1emL7QQrdAm2xxQXtjmg6KLEMhmlFqGeuDjCWhZxCN7OJ29XLmAgWtjjY0zMXhMFgaBFCbVwzjrI/nWM0l6Pf6aPd6q3QW7CtbhJ0cjgdZygjmDwEBoOhWYTeLTCay6Io7RIjVjHbvkU82kubtpPK2WSNXTUYDE0k1MZ1HEGwqjycsqx2zrXfwtKOKH3xI7TZphRMOYoHnkq6/avutxe0T1z8h8IO0zbVscFQG6F2C4yjKFl1cCqEYgkWURFilvvQJWErJlrAYDA0i5YwrlmUIZKkdLhsn5wzyM/Gvs0jQwdZ3L+P49qyDZTQYDAYCgm1W0AE2u0IacchpzlsKmXHUhxniEE5TC5nH1OEz2AwGBpJqI1r3BK62mzSjs2BlMU+7an6nrSMsePwHPalQv3Rmkp3rLB94byjsasPbCo8NpQpHKVe2L6osAPr6iiZIcyIyCLgLmAubijOGlW9pajPauCHwFZv1w9U9aZGyhkWQm2BUo6yP+2QsCwWtNvsHuqr0NumK3ECfc5ctgx2cSgttMUWkcoewnFmRLVYgyFossAnVHWDiMwCHheRB1T12aJ+v1HVS5sgX6gItc91LKf83nmMlzNDnNE3yvLYrLJ9bauT8+zVrIz288vdNi+OpFkZOZeexPIGSmwwTF9UdZeqbvC2h4BNHFta2+ARauMaEWEBJzLbaieds8lUqHOmOGRUyXjOVkeVDGlymmmUuAbDjEFElgJnAI+VOHyOiDwhIj8VkVPKvP9aEVkvItM2mC/UboG4Dcu0j56oRTJ31HCWI6U5oo5gi1stNiVJHMcY12KOFKUHOH9l3l1dkc/VlsJwtq89Ny8gqQytgoh0At8HPqaqg0WHNwBLVHVYRC4B7gNWFJ9DVdcAa7zzTcvHz6GeuSZzylPONg5nHF49ex+LO+yK/dutCAnbIqNKTGyW6HF02nMaJK3BMP0RkSiuYf2Wqv6g+LiqDqq6MZNeMcOoiAw0WMxQEGrjmnGU3dlNDGYzLBzYy+xErmxfwSJuuQsJcqpEROiLRmmjerIXg8FQHRER3NLZm1T1i2X6zPP6ISJn49qYyhnupymhdgvkVEllDpGJO8zqHqLDrp7PVQSi4roGLMAK9/gRCrpnH/TdtytqVr3NYM4F3gs8JSIbvX2fARYDqOpXgcuBD4lIFhgDrlSt8LBkGhNq4wrgaIocOUQUy8fvWtVNVWjjGlqDwVAfVPW3VFlTrqq3Arc2RqJwU3VaJyKLROSXIvKsiDwjIh/19veJyAMi8rz3f6V8gDUxIkl27ZzHnmTlscBRJekoW9nNwVyK9ogQJVbxPc1GRG4Xkb0i8nTevobp1mAwBIOfe+bxwOFVwOuBj4jIKuB64EFVXQE86LXrjmCTkiQ7j/QyknVztpaqAqua5VAuzWA2g4WFIK2yBPYO4OKifQ3RrcFgCI6qbgFV3QXs8raHRGQ8cPgyYLXX7U7gYeBT9RRORIjYszjAdu7e+jqOZHKcEX87z7OBI2OFi0IcHeX36R/SHV/MedbriUWEsawb6xpmVPXXXsxgPoHrNp+XtizLa20pOPadI3cVtP9xyXsK37w/IKEMhhZnUj7XosDhuZ7hBdiNu9641HuuBa4FaLfKr7AqRVSEgfgK5uhC5rdBwrZJj7YTLZk0W8k5Q4xmD3BAU/TaMeYkbOKZlszr6ku3BoMhvPh+lF4pcNh7GljyJlxV16jqWap6VqJiJYFjaY8Iq2OncUlfL5efsJXzZo8wLxGlo4wLUjVNMr2Tx3O/YFdumOWdWfp9JHsJM5V0m7/KJaljDZbMYDBUwpdxLRM4vEdE5nvH5wN76y2ceP92J4XvbVnGoXSMv1hygFP0+ApvsojZnTg4HEzbjIXcLVAGX7qtZeAyGAzB4idaoFzg8Frgam/7atw0Y/URSo6+FOW5kVG+sPMrvDIa5b9+4LucPVA+GkSI0m714oiyYxQOWf5jOENEYLqFQv1aAqd/6HcTr2IcZ6jgNSuSK3gZDIbS+Jm5jgcOv0lENnqvS4CbgYtE5HngzV67Low/5S9+2m+LIm1CtMJS5Hi0nwuip3NSrJeRrENKwn27LCLfAR4FVorIdhG5hgB1O5MwYW6GZuInWqBS4PCF9RXnKKXCqGwB2mPu/2Voj/RzRl+WA6kIjx/KkZVUUCLWBVW9qsyhwHQ7g7gDN6A9P+RhPMztZhG53msHFolhmLmEcoWWJRD15tTJvDvPXWPCoV8s4JXR8mIfSm7hK3vncKKzhAvnWuR2n8QuHglY4tairSj/zeZ/f83E9kjyHQXHOhIfL2i/67zfFrT/+/P1la2ehCHMzTBzCe3Ce5l4ef8kylDGYdfLC8g4EI8eh8ixq68cZ4htw79gvw5zYtcgs2PxhstuCDW+w9xmQs5RQ3CE0rg6CiNZZSynRC1YEEvwXxLvpSdm8eutJ/DJN6xn8H/v46qeDxzz3ojdy2ntf8H5Pb28etkLLO5owgcwtASVwty84xPRGA0UyzBNCKVxBcgp5BzXRZCwhbmxOFEL9qWizF62ndQH/hcL2499nyVx+rWL3liOju4hEnZrrIE1NIzAQwgNBgBpZDYwEdkHjNB6iyYHgA5Vnd1sQcrh6fYlXFnDpF8/8iwJSreez/XHqnqq1/7fwIG8B1p9qvo/fJwnrPqtxLisgem3HuTpNp8g9VzPc5fVbUONK4CIrG+126xWkjlssjZTHi/MbTXuj2kP8FncsiP34uYgfQm4QlV9B0OHTb+VaCVZiwlS9kbpJZTRAgZDPTBhboZmElqfq8FgMLQyzTCua5pwzVppJZnDJmvY5KmVVvo8rSRrMUHK3hC9NNznajAYDDMB4xYwGAyGAKjJuIrIxSLynIhs8cJaDAaDwUANxlVEbOA24G3AKuAqr7ZWuf4tYYgrFGS8UUR2FGUGC1oW3zoLg35bKQvVZPUVBv2Wo5X0nk81nYpIXETu8Y4/ViJPRKVzl/wdF/VZLSJH8n7TN9T2iYrOP1Wfq4icA9yoqm/12p8GUNV/LtHXBja3SWJ5V6TL9zUStkP/gsNukoFkjkP7+9iaPDAleUshEmPA7vFVsnswO8iYJj+pqp+vmwAVGNcZcBGwHVgHXKWqz5bq2yaJrF/dLnxV4ZpgxzmaOeyPf9w5daGLmBud46vfYHaQUWesYYXQJ6PbvP7ZRskXEP+iqqFJUFP0Hbzg5z1+/p72ZBq/4E5VS/7t1hLnugB4Ja+9HXhdcSdxa2j9HTAQtaJcPefdvi+QsJVF0SR/Gmzjtv1rSWePAHbV9/klHp3PFb2X0RGpPsDcufcexjLJul3bB2cDW1T1RQARuRs3o1MpA3B2V6TLt27/aV3h1zQ6cvRvu2vWTVMU91j8ynPn3nvqdk2fTEa34/2p599eY8kB/Dnhyv418R24+fir6/YvB6r/PX1x17/VLtmkKJ8wPvAHWqq6BvhfwHfbrMmVIrFE6YmliFuQSu/GcYYCkXESXCciT3q3YUHfZpUavBbkdxjP2gT83zEn3EnBQ0ZV3UKhfhslWIDUpchlHW/li7+DaUctM9cdwKK89kJvX91osx1WLXiFkWy0nqetheNxsyj9A/AF4P3NFMYbuNaIyOVtVtt3/b5v21/cVtDunt2SpXACJ1+/gG/9jvPx+R8uaDd+VlVAzTGXec9ZJtwpIrK2yJ1yDXBIVU8QkSuBzwH+b1enEbXMXNcBK0RkmbiJVa/Erf1UimJD7IsDqQjf2HgaGw918tH5H+TctvfVIG7tqGpOVR3ga0zcKgbGZAavug5qM4DJTgymg37r4YycuJVX1TQw7k7J5zLcJOQA3wMuFPe+v5gp2YRWYsrGVVWzwHXAz4FNwL2q+kyZ7uuAFZO9xt6kcMueb7H+8BifestDvHNBaFIhvAN4umqv2pjM4LUuYFmmG5PR7Xj/VqceRS79uFMm+ng24gjQX+JcpwOrReTJOsgVSmqyVqp6P3C/j35ZEbkO+Mlkzt8RgXPi7ySKxSfWvpGnUvumKmoRNgMdr2auLp0oJ+MHEXkK9/ZqG/DBOglTkjyd/RzX2397ucFLVbPzYv5dan988YSC9rvuq88DpfPamuol8c1kdJvXv2HyBUSoilyq6ldF5GXgy82WJSgaNhVU1fsnYwAA2iPKq7ra2DKU4duHvkId3EYAiNjM1+XMpxdrEudU1dPqIoD/6/kavAyTZ6bpdjJpFSvgx50y3me7iESAbqBk/OT4dyBSoZxzCxOa++xSJCxlWXcKSPDAWBTVDHUxsOqQkiRpJ0fIVWBoYZr8ACsIJtwpuEb0SuA9RX3WAlfjlou/HHhIZ2gCk9BbFkuUNlvpbTuZofROMtn6uAYcHJy6nMlgmBmUc6eIyE3AelVdC3wD+KaIbAEO4hrgutBqg1WojevupMVXDj7BedbZPPUOh28/+g4++WIdsoWJRad20WmF+uMHRsYpdDSnv3J0O/ahqZ83Lq0aZG/wSyl3iqrekLedBN7VaLnCSOizYlnYWAJi53wtU/V9XhWmwUMKg8EQUkI9dZuXcPhs72nsGBUu+t7J7NDf1e3cKUmRdHK0wPhiMBhakFBbFgdI5txbzXn0Mcv2lwjELxZm5mowGIIh1DPXsaywbijCnITwtyeM8JMdJ3PH8EN1Obc1g03rxkOF2bM61lye16oc83pyxzsK2ptG/mNiuy8ammXKBkPTCfnMVcgppB04nI4zlq0e0SFESMQWErFLLQo5Sru20WbbGLerwWAIglDPXMcZy8IrowkOZqqn1LSsDhZHz+BgdCf7R8rlfrXokgSdEYt6LUwwGOrB4Y8uPGZfzy3bmyCJoVZCbVyjlrKg3Z1ajmSFMa1uXOPRXs6JL2bL2AD7ebxkH8EmYVkkbOoagdAq9MUKc1DuS/pPBfmxRT0F7Q/+6ej24g4MBoNHuI2rQG8iSzJnsT9lkfGRDL7N7uXUngxZbeeRCilOY55xNRgMM4+sc2fVPhHr6pquEWqfa8qBbcMRBjMWyzoyDNjtvt5nW1p5RioWcRuiFjP2oZbBYAiWUM9ccyocSCkg9MfTzIq045rDyn7SnCM4VVyptghRy/hbDQZDMITauGYceDkzRHuki5UDe9k6vIT2sSUkMwfKlnwZTG/nvl2vZof9UsVzW8zcWevBdKE/5JITtx5tbKr83oRdvmaQPVMVWkc6v/T/HbvzltpuTw3NIdRuAQVy5Mh5SXUiltIe6ce2EuXfow5jpMiSKtsHMCFYBoMhUEJtXGMWLIv2YIvws21L2Dpsc7xzCu3R2WXf0x1fzLvnd3J+dFUDJTUYDIZCQm1cLZT2iDvF3J20SOaUbkkQtzrLvicunSzvHGZeAmbujb/BYGg2ofa52hZ0RWE4A1uGU3RHoiztiPLi6Oyy1da6GeDMFZs5nD4NdjVU3Jbllf3l7wSKufh1jxXuKFscxTAVrup9rHqnJiEii4C7cMt0K7BGVW8p6rMat17XuCP/B6p6UyPlDAuhNq7ghktFLIiKRXfUYlFHjq7h7rL9HRwy6dgxOUsNBkPNZIFPqOoGEZkFPC4iDxSV1gb4jape2gT5QkWoLZAAMUtpj8CsSISFHQ5n9B9gvt1V9j0pSXLoSBeHM6EfNwyGlkJVd6nqBm97CDe2pLj6q8GjJSxQTmEkl+PJQ8ILQ7N5kj+V7dvl9LD8xA28dLhy4haDwTB1RGQpcAZQyo9xjog8AewE/r5UZV0RuRa4NkgZK9EI90tLGNeMA0NOmhetzew6/EjFvl3aQe95W1m+ZVmDpGt93vJPjx5tvLVy3753Hi7ccXv95TGEGxHpBL4PfExVB4sObwCWqOqwiFwC3AesKD6Hqq4B1njnm5areVrCuJ7ak+KjZ77AC3sW8us9H+Znh/fwzOj3S/YdJcnY07M5MDKLRGwB6cwhHB1psMQGw9T47pFwF+ETkSiuYf2Wqv6g+Hi+sVXV+0Xk30RkQFX3N1LOMBB646rAoo5hVr7/cZb8sZ05j5zFy08sK/OQWshIhsOvzOVIKkHC7iGbG8PJGeNqMNSKuEXnvgFsUtUvlukzD9ijqioiZ+M+1ymX+3NaE2rjaon7zTxzuId9N1xBfzzJ/K4jJfMGiCRY0X4RS6WfR56N89j+bgaTW1GtvFJrJhIvyqnwh388Pa+1o+DYl0/4m4L2bR8tPtvX6ieYIeycC7wXeEpENnr7PgMsBlDVrwKXAx8SkSwwBlypqtPytr8aoTauACLK4bTF5sF2TuqK0ZsYm1gOW9gvyiKdR0/c5qXhDnaNKo6OYpJhGwz1QVV/S5WVOap6K3BrYyQKN1VDsURkkYj8UkSeFZFnROSj3v4+EXlARJ73/u+tt3COQtoRLIEF7cqRjM3Pth/H87ljlxDYVoLTu6Ms7XDYNhJhRzqJMawGg6FZ+IlzHQ8cXgW8HviIiKwCrgceVNUVwINeu+7kuwDSjnAkLaQkeUw/wSZiuQlZkjl8JdYOAyJyu4jsFZGn8/YFPnAZDIZgqeoWUNVdeAtJVXVIRMYDhy8DVnvd7gQeBj5VbwFtgWRO2Jt0FxP0RJUosWP6OZpi15jQEREyDjitM2u9A/c26q68feMD180icr3XrptuU07hnd2Pti4t23fbSKGuYyYHrsHgi0n5XIsCh+d6hhdgN+5641LvmQgW7rJnTUnItAN7UmkGNEZ/HCwtPeEen+UmbIiF350MgKr+2tNrPg0ZuAyGmUojQt58L3+tFDjsPQ0sOaVR1TWqepaqntVm+S+El89gRvkjv2d7egRbwCoptkXUgnZb6Ysrs6xjZ7cthO+BS0TWi8j6MadCwTCDwdBwfBnXMoHDe0Rkvnd8PpRNVFUz8xLwzo4LOLGtk61DcMjaV6KXQ8aBrApRccu4TAeCHrgMBkMwVL13rhA4vBa4GrjZ+/+HgUgIHD8rxRtPeI4Hnz+JL+3cwYHMiyX7pR0lq0LEUiKtbVz3iMh8Vd0V9MAF8L4zNk5s37y98NhQprB9zuzRwh2FYbEGg8HDz8x1PHD4TSKy0XtdgmtULxKR54E3e+1AGMpEeG7XQtoiWf56YAkrI+ce00fVYSSbI5WD7miO/rhFe3wptlU+PWGIGR+4IOCBy2AwBIOfaIFKgcMX1lec0gxlLZ473M3CjlEuXf4Cmw6vYGNRH8Vh1MmSdiJ0RLJ0RaP0RZdyQB3G0kcaIeaUEJHv4D68GhCR7cBncQeqe0XkGuAl4IrmSdi6iMjtwKXAXlU91dvXB9wDLAW2AVeo6qFmyWiYvrTEI/XtIxa/SW3jfbOXcNl/fYLFm1dAsb1UhyzKwXSOh/ckGMnmWJBbzFjkCGPpl5sitx9U9aoyhxoycAEs/sc8l+6PCo/1xwvdvX91x4aC9gdeF5RUdeEOGhzmZjCME+pk2eOM5pSXk38gmRMSJx6gJ1q+vHPGcdiTSpNRZWG0k26Z10BJDWFCVX8NHCzafRlueBve/3/eUKEMM4aWmLme1Z/lb1ZewOmnPoRz0ol0lTCulhVjWVsbJ3VlufTELQzMPkDfSdv4yp1X8vEtTRDaEFZ8hblB8xM6G1qblpi59sQynHric3Sf9BJOZw9RyynRy6LNhv54hkUnbmXgtX9C3rKMxR3DDZfX0BpUCnPzjk+EujVQLMM0QRqZDUxE9gEjQKslzh0AOlTVf5nUBuPp9iVcWcOkXz/yLAlKt97qtx/nPdB6DlidF+b2sKqu9HGesOq3EuOyBqbfepCn23yC1HM9z11Wtw11C6jqbBFZ32ozAU/mpc2WoxLjX3DY9Bs2eZhifHZY9VuJVpG1lHEKUvZG6aUl3AIGw1TwwtweBVaKyHYvtK1h8dmGmU1LPNAyGKZCGMLcDDOXZsxc1zThmrXSSjKHTdawyVMrrfR5WknWYoKUvSF6aegDLYPBYJgpGJ+rwWAwBIAxrgaDwRAANRlXEblYRJ4TkS3eOu269G0mFQoy3igiO4oyg4WGMOh3OtcDC4N+y9Gqeq+mUxGJi8g93vHHSlTsqHTukr/joj6rReRI3m/6hto+URGqOqUXYAMvAMuBGPAEsKrWvs1+AfOB13jbs4DNwCrgRuDvGyzLxcBzwBbg+np8FwHLez7wGuDpvH3/Mi47bpKUzzX7O56MbsOk3+mg98noFPgw8FVv+0rgnkmcv+TvuKjPatwFJoF8xik/0BKRc4AbVfWtXvvTAKr6z+X6xki8pd2afB0tESEikMw5DOsRlBxQagnsZInQZfUiVCnGDow6Q6RJflJVP1+HC1dFRGzcP4iLgO3AOuAqVX22RN9zYiR+51e3Uavw0ybso38Dr6RKVXmYGj2Wv0VBo84QKR1rWHbzyejW638O8Ltar/vqOceWHtq4N13QjpfIP5xy6pIyc7P6WInWKPLth4j4MkKn9bZX7WNH/VV93rS/euUOv3pX1ZJ/u7XEuS4AXslrbweOSUDnJb/4FNBlS4TVHe/2fYEj2QyPZH5M1hlBnRQicSJ2P9ncEKrHlteeLBG7h9fG30m7ZVctC/PwyD2kneR1IvLXwHrccuNB5gE9G9iiqi8CiMjduBmdShmABe3WLN+6Pa690Bt04qyjP/CPbfnaFMU9Fr/yPDxyT92u6ZPJ6Bbcv3XcydbUefiq+cfs67mlsPTDorYLjumzZeQnNV0XclAhQc1kEJGLgVtwlfF1Vb256HgcN8XjmcAB4N2quq3EqYrsR3Xd3v/Wk6r2mTX3QNU+AGd9/fSqffzpvXyGvsAfaKnqGlzj+sO4TK7OU7sd4VXRN7Og/bWoZnCcUXJOEtTf6FQNx0nzkuxkd27EbyHu44FX45Ya/0JdhChPqcFrQX6H8QKFwOdSagoUToKquoVC/TZKsACpOebSm/HfBrwN11V2lYisKup2DXBIVU8AvsT00N2UqGXmugNYlNdeSPmKSsV9fTEQs3nn3AhPHz6JLw7/CsjhOEOTl7QMjo6wZeQndMSPZ55eVHX2qqo5ABH5GvDjugkyRbyBa42InBOXNt+3rZ//0P8taLffGN5KDc0kX79MwS3wypWFs6OeW56o+p7aZ6llqUcdNj8z/stwn08AfA+4VUREj/U/TskmtBK1zFzXAStEZJmIxHAdzmsr9Z3sBdoi8Kp5O1jZPYZU9YpOHa0wtS/DO4Cnq/aqjckMXusClmW6MRndwvTQbz3qsPmZ8U0oct0AABqySURBVE/0UdUsbs2Q/hLnmrAfdZArlEzZuHqKuw74ObAJuFdVn6nSd1K028oJr9rESX37QZofkisiT4nIk8Abgb8L+HK+By9Pvwb/TGZiMF30G7YENe/HdVhuarYgQVFT4hZVvR+432/fXnuOv/MCh7JpoqNx1v3+tWzcNxu0HtEBtaGqpzXwWlkRGR+8bOD2coPXZLnj25cX7flGPU7bMgSp27CiqsXlbqaCnxn/eJ/tIhIBunEfbBXLswZvjb/faIFWI5RZsRxVxkizPy1s2DebLUNRtHZ/fMsxmcHLMDmMbqdE/q38DtwZ/3uK+ozny30UuBx4qIS/dUYQSuMatYSTYl1kHOW+XSPstF+kPnGtBkPjmP/tjxfuuPvq5ghSJ8rN+EXkJmC9qq7FvQ36pohswS0OeWXzJG4uoTSugtAVhZGs8Lz1NMPpPdQhksRgMNRIqRm/qt6Qt50E3hXEtY8ZrEoQsfwOYNurd6mRUBpXRRnMCIfTOQ6NbSHnmCKD9WTH2LErhQwGQ31p/iP4KjiaotIqCIPBYAgjoZy5CsLsuGKLjYzYxiFgaEl+9tqmrzMxNJHQzlxtC6IWk45vjdj9vKbtPSzsXB2IXAaDweCHUM5cLYGogD2FRVlLE6/n38/dyS9fXMHHtvwK8yDsWGbHpx4TP3JDYVrQjpuCzF1jMLQuoZ25Rix1Z66TJK4JensP0xXN1F8og8Fg8EkoZ64AccshYQsySfsfJcasOQfpTdSektBgqIVLH/9us0UwNJFQGldH4XDGZigjdMTmMZqJkM35y9M4LINs27SC7cOdRCMDdcv9Op14fsh/KNaJHW8vaP/iR8UJixuei9VgaAlCaVwV5UjaYiwH3ZEFKA5DPo3rCIfZtHsZO8ZitEdnM6IO2ZwxrgZDq+N/gUA4CKXP1VE4kFIGMw6zc/PojiygeiEWm+62VcSlk3tfmsXmQeWNkQtY2HZWI0Q2GAyGAkJpXBUYyeUYzeXopI12rV4bSsSmxz6OmMZ40tnG/kyapZ0WAzl/dZwMBoOhnoTSLeCoslMPA7As0sdo9tiibcUIURbmFmFjsdPaDYBlwrBKsj/pXy8nWwsL2i8MTYfUpgZD8ITTuAIpcf2kAth+JthikZAIFoLjZdCyLQKtYGAwGAzlCKVbACCiESwsDmfTDFr+6mbl1CGjOcYYxAIG4lk6iQcrqMFgMJQglDNXC+jRLhx1SFgRojr5LE6CELWUSAjKwxgMhplHKI1r1BJWtbUTtSDrQG6kus91HEGISydxyyZuZbEllB+xqdzwhqcK2vf8tHzfSFFF3A/+6IWC9sdPrptYhpAjIouAu4C5uM+d16jqLUV9VuMWQ9zq7fqBqt7USDnDQigtj6MwmoX2CJw4K0NOozBqUS71oCUdxCLd2GKRU4dBZzezosdzwfJN/GnwNH420lj5DYZpShb4hKpuEJFZwOMi8oCqPlvU7zeqemkT5AsVobxnVmBnMsVIVlm9eBuv7a9UWlvojC9kIHYCCcsmi3Jo9BnmtQnHfy7Dm+fvb6ToBsO0RVV3qeoGb3sIt3JrcWltg0cojWtWlRftbbyUHMOyHGJWpfpZymhmP4PZXeRUJwoZrj8yzOMf6WPtKwONEdpgmEGIyFLgDOCxEofPEZEnROSnInJKmfdfKyLrRWR9gGI2lVC6BTKOw47UH0knxrDtGNGKxhWyuQMMa5pMwpkIw1qfuZ+/3Hg6+zM/a4TILUV7x2hB+9y2901sPzL27wXHijOT3f5nywvaHfGXJrZHUoX+WMP0REQ6ge8DH1PVwaLDG4AlqjosIpcA9wEris8xE0prh3LmGrUsViTOZ64u5htPreJnO2exsPN8OuLHV36fWLRLjLb4QpbEz+atbStZZb2BiN2PiKkbZTDUiohEcQ3rt1T1B8XHVXVQVYe97fuBqIjMyNvHUM5cIyIs0zmkcHhocDcWFot1CblIpuzsSLCwRQCLWZF5LHTmcUpPiiPpWWxmLsOpLDlNN/aDGAzTCBER3NLZm1T1i2X6zAP2qKqKyNm4Ezh/WZemGaE0roI7e+2ybc7vns1gxmLDoTSW2GXfozhkHIe4ZXFy7hRmx+IcSCkn9ziczPl8e/8ONo/8qHEfIsSs37yyoP3Ap45OQNpvLOybzBXesb0yWngH8M2TXzux/RcbjVtgmnMu8F7gKRHZ6O37DLAYQFW/ClwOfEhEssAYcKWqTsvb/mqE0rjCuIEV5rWlaLejzInF2J3trfieHIotQk8kRtSCAymLxR0Zjp81RP/evsYIbjBMU1T1t1RJT6eqtwK3NkaicFPV5yoii0TklyLyrIg8IyIf9fb3icgDIvK8939lyzcFDqdz3PtyhL2pCJ9/2yP8t7mVM1w5qhOpWl5IDnPXkf/kjwcjWKJY4XQvGwyGaYofizMeOLwKeD3wERFZBVwPPKiqK4AHvXZdyajykuxkKCP0Lt/O7HgFn6k6DJFkMJtBgQxZxjL7GczkOJxKkCKcNbVE5HYR2SsiT+ftC3zgMhgMwVLVLaCqu4Bd3vaQiIwHDl8GrPa63Qk8DHyqnsIlnSwvpn7NNhZixbLYFUKyHB3lj6kfMSu+iHP1PDppY07iVA45Sf5zVwevWBvqKVo9uQP3NuquvH3jA9fNInK9166bbr+1tXA58dsT5QetHw4XhmZdxvsK2i8MGXeLwVCKSd0rFwUOz/UML8Bu3PXGpd4zESyc0rFJCyhYjDpZDm9ZSMax6G8/g4jdX6Kn4jgjpJ1hAGyETnqwsEg7Si6kM1dV/TVwsGj3ZbgDFt7/f95QoQwGQ834Nq6VAoe9p4Elnwiq6hpVPUtVz4pLm2/BFDcJSyI6wKCM8p8bzmIwE+Uvu97A8YnzyrwnS85xZ2Fxy2a2M0CHRFsxp2tDBi6DwRAcvoxrmcDhPSIy3zs+H9hbb+GiYjE/chIAP93Rwe6xKK/tH2KhzvH1/iy5lq9FEMTAZTAYgsdPtEC5wOG1wHg5xqtx04zVDQHabJuTZRGWCvcc+QovDcMFpz7J8o7qq61yqoxJiqw6WAIW5WNkQ0igA1fCloJX+kDXxKsY1WTBq5i+uEy8DAbDUfzMXMcDh98kIhu91yXAzcBFIvI88GavXTdskWNyiSZsoa1rmEQVO5lTJasOObJY4hoQm2g9xQuaQAcug8EQPH6iBSoFDl9YX3GOEhEojg2IWBDvHiFmlb/ZV3VwVMmhZCSNpULCdh+MhRER+Q5u1MWAiGwHPos7UN0rItcALwFXNE/C1kVEbgcuBfaq6qnevj7gHmApsA24QlUPNUtGw/QltCu0Uo5rQKOWYOfcqeqLIykeefgNvDwCEbuXXG4IpbAaaSZ3kEedX2JJFFujdGsPyVwUPcZUhwNVvarMocAGrqIVrXz9P/5sYjvrFD4sjFhXF7RvfP2fCtqdHUczkX/tvjoJWD/uoMFhbgbDOOGczuHe2udUEYQIFiJRjjDKs4f6yThKf2Iltj3rmPepphlKPs9Q6hUALISoFd6ZqyE4TJiboZmE3uIoSp/dxusTV3FKWy8iyhffso7t/7qeq7rfU/Z9pyQu5rbjT+OGVaO8/6RtnKKm2JMB8BnmBjMjobMhOEJtXC3vgVZUhDmRdmZ5z6TmnvICzl//G4vay/tee7WLk+buYtnc3czt30+H3VLRAoYGUCnMzTs+EerWQLEM0wRpZDYwEdkHjACtVthqAOhQ1cqZY5qIp9uXcGUNk379yLMkKN16qwp/nPdA6zlgtaru8sLcHlbVlRVOMX6esOq3EuOyBqbfepCn23yC1HM9z11Wtw19oKWqs0VkfavNBDyZlzZbjkqMf8Fh02/Y5OFomNvNTCLMLaz6rUSryFrKOAUpe6P0Emq3gMFQC16Y26PAShHZ7oW2BRqfbTCME9pQLIOhVpoR5mYwjNOMmeuaJlyzVlpJ5rDJGjZ5aqWVPk8ryVpMkLI3RC8NfaBlMBgMMwXjczUYDIYAqMm4isjFIvKciGzxlhIaDAaDgRqMq4jYwG3A24BVwFVeba1y/VvCEFcoyHijiOwoygwWtCy+dRYG/U7nemBh0G85WlXv1XQqInERucc7/pgXs+z33CV/x0V9VovIkbzf9A21faIiVHVKL+Ac4Od57U8Dny7T1wZeAJYDMeAJYNVUrx3kC5gPvMbbngVsxh08bgT+voFy+NZZWPQLnA+8Bng6b9+/ANd729cDn2v2d+zJcjHwHLBlXL56fBdN+iwto/fJ6BT4MPBVb/tK4J5JnL/k77ioz2rcBSaBfMYpP9ASkcuBi1X1A177vcDrVPW6on7XAn8HHBch2tUb8T+Axm1lzsABECWXinFwsItXUvumJG/pzxClz+rF8pHneSg3SFKTn1TVz9dNgAqIyDnAjar6Vq/9aQBV/edSfROS+N0s+9hk16VYfHpHQVuHd01sb3ju2ITYU2V2xF/FiKHcIGPOWMOybXt3XZuBi4DtwDrgKlV9tkz/c4DfNUq+gNisPlaiNYr8v28RafhT9TPPXFa1z+OPb/V1LlUt+bcbeJyrqq4RkYPAxb2R3mve1X+l7/ceScOvjjzDcG4/o5n9ZJ0RqGNFgVhkHm/vegftPrTw3QN3k8wmrxORvwbW45YbDzIP6ALglbz2duB1+R28getaoDciUfzq9v9fd3ZB2/nNP05sxy54fmrSlsCvPN89cHfdrumTs4EtqvoigIjcjZstq6Rxxf0uqOffXmPJQYUENZNBRC4GbsFVxtdV9eai43HcFI9nAgeAd6vqthKnKvr7bqxuH1v3D1X7FKfbLE2u7JFaHmjtABbltRd6++pG3IalueX0WYtIZ/fhOEP1PP1UOB54NW6p8S80WRbUSywCfKrNMjW0JkGpgWtBcafxrFjA5xolWIDUPDv0+ZzlGuCQqp4AfInpobspUcvMdR2wQkSW4RrVK4FyOQCLDbEveqLKuxdaPHNkOf9nRJpebFBVcwAi8jXgxwFfbjKD16QGta+f/KuC9jdefn1eq34z11ZHVdcAaxrpFsg6dx6zz98Mqir1qMPmZ8Z/Ge7zCYDvAbeKiOix/scp2YRWYsozV1XNAtcBPwc2Afeq6jNluq8DVkz2GhkVdozFGMpAX/tpxCLzpipuvXkH8HTVXrUxMXiJSAx38Fpboa/BP5O965oO+q1HHTY/M/6JPp6NOAL0lzjX6cBqEXmyDnKFkpp8rqp6P3C/j35ZEbkO+Mlkzp/Kwb4kjGRzLNdTeTkeZ09291TFrRkReQr39mob8MEgr5Wns5/jOqRuLzd4qWp2TrQuLrWZwmTuusa/i0bJFhShSlCjql8VkZeBLzdblqBoWOIWVb1/sgbAErcKbMyy6HISxKQ9IOn8oaqnNfh6vgavybJtJFHQXh472l43Vu+rhY/JDFzTBVUtLnczFfzM+Mf7bBeRCNCN+2CrlEz3A/c3I1qgEYQ+K1bUcqeKCccmqvFmi2OYJgQ1cE1z/Mz4x/PlPgpcDjxUwt86Iwi1cbUFemKQzAmpnEU0F2u2SAaDb/77vI8UtP91921V3/P78+8NSpyaKTfjF5GbgPWquhb4BvBNEdmCWxzSf+zlNCPUxhXAQrFEiAhENPTiGgzTmlIzflW9IW87CbwriGsXD1al8DOAQWMGsVBbq7EcPDOYIio2/bFQi9pSDGYKH868af7oxPY9RxotjcEwPQl9ysEMDg5KR0RoUxMobzAYWoNQTwcjAvOibfTFhVf1pDiQmoUpIG9oFfzeouZz3m8nFa1oCDGhn7lGBMZvYv0kWDEYDIYwEOqZ6zg5hZGsTcqZkREdgbOwo+k5GwyGaUeoZ65ZhZfTIxxOK73xNO12qMU1GAyGCUJtrZI5ZROPszszxry2UXpixi9gMBhag1C7BaIiLJZTGLATJHNpMk6zJZqeHEqZKAyDod6E2rhGLFgoPfTGLJI5m7TxuRoMM5apRF+UoxFRGaF2CwCk1CHtKCOZKKnySb8NBoMhVITeuDqq5BxIOxa5mZn/wWAwtCChdgsARMUiYgkxy8Fu/ZyaoSSZq0/9Itvqrst5DIbpQOhnruNzVUu07osIREL/8Q0GQ4sSauuSUzikowxnHUQUW0CIcHTN1tQRSRCzOsyqL4PBEAihNq4AguCoMpZ1PRix6BysmisSCInoHDrtOXUw0waDwXAsofa52gK90oYtwraRGJYop0XexPORDRwZK1divjoiUU61L2COdGAb68rThzvqcp739/9VXc5jCCcisgi4C5iL67Fbo6q3FPVZjVsMcau36weqelMj5QwLoTaulkCbbWOLMJp1Z7FzrA5eoYva0o5adBKn07aMW8Bg8E8W+ISqbhCRWcDjIvKAqhbPdH6jqpc2Qb5QEWq3gAAdESFqwWBGiVqwrDNCN7NrPK9NbzRKd0yMcTUYfKKqu1R1g7c9BGzi2NLaBo9QG1dLIGELUUtI5pRkTsk44FD7OljBGFaDYaqIyFLgDOCxEofPEZEnROSnInJKmfdfKyLrRWTapmgOvVsgYYOjkHQcLLFIO0JWsnU5tzGuLpPJ2TDQcWZBe//I4xPb0VAP1YZ6ISKdwPeBj6nqYNHhDcASVR0WkUuA+4AVxedQ1TXAGu9803J1UEv9HGwRYlblQoVChERsIRG7t4GSGQwzAxGJ4hrWb6nqD4qPq+qgqg572/cDUREZaLCYoaCljKuFOzuyKoktEdoj/UTtWQ2Ty2CYCYiI4JbO3qSqXyzTZ57XDxE5G/dne6BxUoaHULsFxrEFEpaFbbkLCyr5XFVTHB7bgpJpoIStzWTcAvluAMOM41zgvcBTIrLR2/cZYDGAqn4VuBz4kIhkgTHgStWZmRSkJYwrMJFXIFf1a1IcHQlcHoNhpqGqv6XK8khVvRW4tTEShZuqbgERWSQivxSRZ0XkGRH5qLe/T0QeEJHnvf8Dc3JaMl6o0P1e6xEtYDAYDEHix+c6Hji8Cng98BERWQVcDzyoqiuAB712IDgKGe/OwhaItM6EuyoicruI7BWRp/P2NWzgMhgMwVDVSqnqLmCXtz0kIuOBw5cBq71udwIPA58KQsi0A/szaY6z4syOK+3DnUFcplncgXsbdVfevvGB62YRud5rB6JbgOPa/Wch/5vZHylof21f/bLDGwzTiUlFCxQFDs/1DC/Abtz1xqXeMxEsPOaMTVlIv4KKxOhuW0U8etyUrtVoVPXXwMGi3ZfhDlh4//95Q4UyGAw149u4Vgoc9p4GlnzUpKprVPUsVT2rzZpaITwRiImNJZByhBzlFxG0xY7jz9reyFmRt07pWiGhYQOXwWAIBl/GtUzg8B4Rme8dnw/sDUZEl4gIjsJYTkhLumy/dPYITyUPstXaEqQ4DSPogctgMARDVZ9rhcDhtcDVwM3e/z8MRELcaIGoZZFTGMpASpJl+2Zzh9g4+p2gRGkUe0RkvqruasTAtS/pv8zL48OHApTEYJg++Jm5jgcOv0lENnqvS3CN6kUi8jzwZq8dCBGBnqhFuy1UC0cWSdDTdiqJ2MKgxGkE4wMXBDxwGQyGYPATLVApcPjC+opTmojlLnvNOFQtr21bbSySk9kf3cmu9PZGiFcTIvId3KiLARHZDnwWd6C6V0SuAV4CrmiehK2LiNwOXArsVdVTvX19wD3AUmAbcIWqmum4oe60RMDo4bTyp+RheqWD4xIxlPIWNueMsYPNjGVa4/eiqleVOdSQgQvgy//8fya2b3t/5b4PffBXBe2eLwchUd24gyaHuRlmLi2RuCXnwGHrEBl16IhAXM3DG0N1TJiboZm0hHF9TX+W/zh3jLvevoF/uuLHXNK1uGzfxR3ncd8Zi/jMcZdQjyqxhmmHrzA3mBkJnQ3B0RJuge5olmWnbyLWP4g9J8PsH5ePc+1yelm58kl2DPY0UEJDK6KqWilR80xI6GwIDmlkNjAR2QeMAPsbdtH6MAB0qGptxbsCxNPtS7iyhkm/fuRZEpRuvVWFP857oPUcsDovzO1hVV3p4zxh1W8lxmUNTL/1IE+3+QSp53qeu6xuGzpzVdXZIrJeVc9q5HVrxZN5abPlqMT4Fxw2/YZNHqYYnx1W/VaiVWQtZZyClL1RemkJn6vBMBW8MLdHgZUist0LbWtYfLZhZtMSPleDYSqEIczNMHNpxsx1TROuWSutJHPYZA2bPLXSSp+nlWQtJkjZG6KXhj7QMhgMhpmC8bkaDAZDABjjajAYDAHQMOMqIheLyHMissVb0x1KKhRkvFFEdhRlBgsNYdDvdK4HFgb9lqNV9V5NpyISF5F7vOOPeTHLfs9d8ndc1Ge1iBzJ+03fUNsnKkJVA38BNvACsByIAU8Aqxpx7SnIOh94jbc9C9gMrAJuBP6+2fKFWb/A+cBrgKfz9v0LcL23fT3wuWbrq1X1O5307kenwIeBr3rbVwL3TOL8JX/HRX1W4y4wCeQzNmrmejawRVVfVNU0cDduAo3Qoaq7VHWDtz0EjBdkDDOh0K9O30QpodBvOVpU7350mv8Zvgdc6CXvr0oYfseNMq4LgFfy2tsJv8EqLsgIcJ2IPOndhoXpNivM+vWdKCXEhFm/5Qi73v3odKKPqmaBI0D/ZC9U4neczzki8oSI/FRETpnsuSthHmiVoURBxq8AxwOvxi01/oUmiteSqHsvZmL/GsxM1nulwqrABtzcAKcD/wrcV89rN8q47gAW5bUXevtCSamCjKq6R1VzquoAX8O9rQkLYdZvQwtZBkSY9VuOsOvdj04n+ohIBOgGDvi9QJnCqhOo6qCqDnvb9wNRERmYzIeoRKOM6zpghYgsE5EYrnN6bYOuPSnKFWQc/0P1eAfwdPF7m0iY9Tsd6oGFWb/lCLve/eg0/zNcDjzkzcKrUu53XNRn3rgPV0TOxrWHvo13VRr4dPAS3Cd2LwD/s1HXnYKc5+HeQj0JbPRelwDfBJ7y9q8F5jdb1rDpF/gOrsskg+tDuwbXR/Yg8DzwC6Cv2bpqVf1ON72X0ilwE/Bn3nYC+C6wBfgDsHwS5y73O/5b4G+9PtcBz+BGKvweeEM9P59Z/mowGAwBYB5oGQwGQwAY42owGAwBYIyrwWAwBIAxrgaDwRAAxrgaDAZDABjjajAYDAFgjKvBYDAEwP8DBjSMsm4OK+8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD_j-zqmDHGz"
      },
      "source": [
        "## Play with different number of filters ( 32 or 16)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UMwOOZfCJ4Q",
        "outputId": "f8ae87d7-ec3a-4875-cfaf-19b81ccc623f"
      },
      "source": [
        "# load data\r\n",
        "mnist = tf.keras.datasets.fashion_mnist\r\n",
        "(training_images,training_labels),(test_images,test_labels) = mnist.load_data()\r\n",
        "\r\n",
        "# Reshape 2-D image in 4-D tensor\r\n",
        "training_images = training_images.reshape(60000,28,28,1)\r\n",
        "test_images     = test_images.reshape(10000,28,28,1)\r\n",
        "\r\n",
        "# normalising data\r\n",
        "training_images = training_images/255.0\r\n",
        "test_images = test_images/255.0\r\n",
        "\r\n",
        "# Design Network\r\n",
        "model = keras.Sequential([keras.layers.Conv2D(32,3,activation='relu',input_shape=(28,28,1)),\r\n",
        "                          keras.layers.MaxPooling2D(pool_size=(2,2)),\r\n",
        "                          keras.layers.Conv2D(32,3,activation='relu'),\r\n",
        "                          keras.layers.MaxPooling2D(pool_size=(2,2)),\r\n",
        "                          keras.layers.Flatten(),\r\n",
        "                          keras.layers.Dense(64,activation='relu'),\r\n",
        "                          keras.layers.Dense(10,activation='softmax')\r\n",
        "                          ])\r\n",
        "\r\n",
        "# model compilation\r\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\r\n",
        "\r\n",
        "# model summary\r\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                51264     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 61,482\n",
            "Trainable params: 61,482\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L00r7wudFUlu",
        "outputId": "eb8de5ef-fa18-4540-a167-daeab4b7547f"
      },
      "source": [
        "# train the model\r\n",
        "model.fit(training_images,training_labels,epochs=10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6931 - accuracy: 0.7471\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3474 - accuracy: 0.8754\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2907 - accuracy: 0.8940\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2602 - accuracy: 0.9059\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2359 - accuracy: 0.9110\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2146 - accuracy: 0.9208\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1976 - accuracy: 0.9247\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1802 - accuracy: 0.9333\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1728 - accuracy: 0.9356\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1604 - accuracy: 0.9390\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f15d159cc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zb9p3vZFr2k",
        "outputId": "5b78f31e-ca03-42d7-805d-06f46505863a"
      },
      "source": [
        "# model evaluation\r\n",
        "model.evaluate(test_images,test_labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2880 - accuracy: 0.9006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28795650601387024, 0.900600016117096]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dagc3ljGS6r"
      },
      "source": [
        "## Add more convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEv-2duVGAIG",
        "outputId": "371278e1-6c04-462a-d15e-a560cee40eff"
      },
      "source": [
        "# load data\r\n",
        "mnist = tf.keras.datasets.fashion_mnist\r\n",
        "(training_images,training_labels),(test_images,test_labels) = mnist.load_data()\r\n",
        "\r\n",
        "# Reshape 2-D image in 4-D tensor\r\n",
        "training_images = training_images.reshape(60000,28,28,1)\r\n",
        "test_images     = test_images.reshape(10000,28,28,1)\r\n",
        "\r\n",
        "# normalising data\r\n",
        "training_images = training_images/255.0\r\n",
        "test_images = test_images/255.0\r\n",
        "\r\n",
        "# Design Network\r\n",
        "model = keras.Sequential([keras.layers.Conv2D(64,3,activation='relu',input_shape=(28,28,1)),\r\n",
        "                          keras.layers.MaxPooling2D(pool_size=(2,2)),\r\n",
        "                          keras.layers.Conv2D(64,3,activation='relu'),\r\n",
        "                          keras.layers.MaxPooling2D(pool_size=(2,2)),\r\n",
        "                          keras.layers.Conv2D(64,3,activation='relu'),\r\n",
        "                          keras.layers.AveragePooling2D((2,2)),\r\n",
        "                          keras.layers.Flatten(),\r\n",
        "                          keras.layers.Dense(64,activation='relu'),\r\n",
        "                          keras.layers.Dense(10,activation='softmax')\r\n",
        "                          ])\r\n",
        "\r\n",
        "# model compilation\r\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\r\n",
        "\r\n",
        "# model summary\r\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 79,306\n",
            "Trainable params: 79,306\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2wsNh6XHnNm",
        "outputId": "08ebc4b9-9055-4863-8ff2-924f5096da71"
      },
      "source": [
        "# train the model\r\n",
        "model.fit(training_images,training_labels,epochs=10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.8683 - accuracy: 0.6727\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4570 - accuracy: 0.8345\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3770 - accuracy: 0.8588\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3351 - accuracy: 0.8766\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3017 - accuracy: 0.8878\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2816 - accuracy: 0.8963\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2553 - accuracy: 0.9059\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2463 - accuracy: 0.9077\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2279 - accuracy: 0.9142\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2125 - accuracy: 0.9193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f15d0776208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5NFy_51HO3X",
        "outputId": "2ff002c3-f67c-42a5-8c0a-df004d62b07d"
      },
      "source": [
        "# model evaluation\r\n",
        "model.evaluate(test_images,test_labels)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3024 - accuracy: 0.8920\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3024091422557831, 0.8920000195503235]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBy3RTY6H_kd"
      },
      "source": [
        "## Experiment with single convolution layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmXgAE8fHmNC",
        "outputId": "62996f86-ada9-4b5f-87ce-bd782e246dbc"
      },
      "source": [
        "# load data\r\n",
        "mnist = tf.keras.datasets.fashion_mnist\r\n",
        "(training_images,training_labels),(test_images,test_labels) = mnist.load_data()\r\n",
        "\r\n",
        "# Reshape 2-D image in 4-D tensor\r\n",
        "training_images = training_images.reshape(60000,28,28,1)\r\n",
        "test_images     = test_images.reshape(10000,28,28,1)\r\n",
        "\r\n",
        "# normalising data\r\n",
        "training_images = training_images/255.0\r\n",
        "test_images = test_images/255.0\r\n",
        "\r\n",
        "# Design Network\r\n",
        "model = keras.Sequential([keras.layers.Conv2D(64,3,activation='relu',input_shape=(28,28,1)),\r\n",
        "                          keras.layers.MaxPooling2D(pool_size=(2,2)),\r\n",
        "                          keras.layers.Flatten(),\r\n",
        "                          keras.layers.Dense(128,activation='relu'),\r\n",
        "                          keras.layers.Dense(10,activation='softmax')\r\n",
        "                          ])\r\n",
        "\r\n",
        "# model compilation\r\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\r\n",
        "\r\n",
        "# model summary\r\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10816)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               1384576   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,386,506\n",
            "Trainable params: 1,386,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_OsdK4JHZQw",
        "outputId": "fe9e0852-5eab-40ac-b490-f1cf093ad9c7"
      },
      "source": [
        "# train the model\r\n",
        "model.fit(training_images,training_labels,epochs=10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5120 - accuracy: 0.8167\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2655 - accuracy: 0.9031\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2143 - accuracy: 0.9212\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1765 - accuracy: 0.9351\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1509 - accuracy: 0.9441\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1229 - accuracy: 0.9551\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0971 - accuracy: 0.9641\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0832 - accuracy: 0.9698\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0667 - accuracy: 0.9754\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0554 - accuracy: 0.9802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f15d065c6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNe8N6pyIlXI",
        "outputId": "7a933925-e6db-4042-f798-ee5c07c891bd"
      },
      "source": [
        "# model evaluation\r\n",
        "model.evaluate(test_images,test_labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3373 - accuracy: 0.9142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.337332546710968, 0.9142000079154968]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvyeevjOJCwP"
      },
      "source": [
        "## **Stop Training** at certain level of accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORNKoQL_Izlq",
        "outputId": "993a7db4-cc37-47a6-b517-b47ffa86bfcd"
      },
      "source": [
        "# load data\r\n",
        "mnist = tf.keras.datasets.fashion_mnist\r\n",
        "(training_images,training_labels),(test_images,test_labels) = mnist.load_data()\r\n",
        "\r\n",
        "# Reshape 2-D image in 4-D tensor\r\n",
        "training_images = training_images.reshape(60000,28,28,1)\r\n",
        "test_images     = test_images.reshape(10000,28,28,1)\r\n",
        "\r\n",
        "# normalising data\r\n",
        "training_images = training_images/255.0\r\n",
        "test_images = test_images/255.0\r\n",
        "\r\n",
        "# Design stopping criterion - callback\r\n",
        "class mycallback(keras.callbacks.Callback):\r\n",
        "  def on_epoch_end(self,epoch,logs={}):\r\n",
        "    if(logs.get('accuracy')>0.98):\r\n",
        "      print(\"\\nReached at 98% accuracy so cancelling training!\")\r\n",
        "      self.model.stop_training = True\r\n",
        "\r\n",
        "callback = mycallback()\r\n",
        "\r\n",
        "\r\n",
        "# Design Network\r\n",
        "model = keras.Sequential([keras.layers.Conv2D(128,3,activation='relu',input_shape=(28,28,1)),\r\n",
        "                          keras.layers.MaxPooling2D(pool_size=(2,2)),\r\n",
        "                          keras.layers.Flatten(),\r\n",
        "                          keras.layers.Dense(128,activation='relu'),\r\n",
        "                          keras.layers.Dense(10,activation='softmax')\r\n",
        "                          ])\r\n",
        "\r\n",
        "# model compilation\r\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\r\n",
        "\r\n",
        "# train the model\r\n",
        "model.fit(training_images,training_labels,epochs=50,callbacks=[callback])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4777 - accuracy: 0.8298\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2494 - accuracy: 0.9080\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1939 - accuracy: 0.9290\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1580 - accuracy: 0.9416\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1270 - accuracy: 0.9526\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1032 - accuracy: 0.9625\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0825 - accuracy: 0.9693\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0663 - accuracy: 0.9756\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0538 - accuracy: 0.9804\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0494 - accuracy: 0.9826\n",
            "\n",
            "Reached at 98% accuracy so cancelling training!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f15d05c7240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIogok1eK5dr",
        "outputId": "286f9c87-2183-462b-9286-4d9127839faa"
      },
      "source": [
        "# model evaluation\r\n",
        "model.evaluate(test_images,test_labels)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3809 - accuracy: 0.9120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38087189197540283, 0.9120000004768372]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_-M3yGFMQJm",
        "outputId": "d8b54d87-73bf-441d-8516-b7be1aace6fc"
      },
      "source": [
        "# model summary\r\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 26, 26, 128)       1280      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 21632)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               2769024   \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,771,594\n",
            "Trainable params: 2,771,594\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}